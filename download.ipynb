{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download\n",
    "\n",
    "Baseball data download routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import collections\n",
    "import pandas as pd\n",
    "from bs4 import Comment\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fangraphs lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = range(1908, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_batter(cell):\n",
    "    d = {\n",
    "        'id': cell.a['data-entry-id'],\n",
    "        'name': cell.a['title'],\n",
    "        'position': cell.small.text.split(\"-\")[1]\n",
    "    }\n",
    "    return 'pitcher' if d['position'] == 'P' else d['name'].split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_game(game):\n",
    "    cell_list = game.find_all(\"th\") + game.find_all(\"td\")\n",
    "    d = collections.OrderedDict(\n",
    "        number=cell_list[0].a['name'],\n",
    "        one=parse_batter(cell_list[1]),\n",
    "        two=parse_batter(cell_list[2]),\n",
    "        three=parse_batter(cell_list[3]),\n",
    "        four=parse_batter(cell_list[4]),\n",
    "        five=parse_batter(cell_list[5]),\n",
    "        six=parse_batter(cell_list[6]),\n",
    "        seven=parse_batter(cell_list[7]),\n",
    "        eight=parse_batter(cell_list[8]),\n",
    "        nine=parse_batter(cell_list[9]),\n",
    "    )\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_lineup_year(year):\n",
    "    url = 'https://www.baseball-reference.com/teams/CHC/{}-batting-orders.shtml'.format(year)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    table = soup.find(\"table\", class_=\"grid_table\")\n",
    "    game_list = table.tbody.find_all(\"tr\")\n",
    "    dict_list = [parse_game(game) for game in game_list]\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_list:\n",
    "    path = \"./input/CHC-batting-orders-{}.csv\".format(year)\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    print(\"Downloading {}\".format(year))\n",
    "    df = pd.DataFrame(download_lineup_year(year))\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for year in year_list:\n",
    "    path = \"./input/CHC-batting-orders-{}.csv\".format(year)\n",
    "    df = pd.read_csv(path)\n",
    "    df['year'] = year\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, sort=True)\n",
    "df[[\n",
    "    'year',\n",
    "    'number',\n",
    "    'one',\n",
    "    'two',\n",
    "    'three',\n",
    "    'four',\n",
    "    'five',\n",
    "    'six',\n",
    "    'seven',\n",
    "    'eight',\n",
    "    'nine'\n",
    "]].to_csv(\"./input/CHC_batting_orders_all.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseball Reference WAR archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11.2M  100 11.2M    0     0   897k      0  0:00:12  0:00:12 --:--:-- 1883k\n"
     ]
    }
   ],
   "source": [
    "!curl -o ./input/war_daily_pitch.txt https://www.baseball-reference.com/data/war_daily_pitch.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For hitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 27.8M  100 27.8M    0     0   356k      0  0:01:19  0:01:19 --:--:--  635k\n"
     ]
    }
   ],
   "source": [
    "!curl -o ./input/war_daily_bat.txt https://www.baseball-reference.com/data/war_daily_bat.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseball Reference pitchers by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = range(1871, 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_player_pitching(year):\n",
    "    url = \"https://www.baseball-reference.com/leagues/MLB/{}-standard-pitching.shtml\".format(year)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text:isinstance(text, Comment))\n",
    "    table = BeautifulSoup(comments[16], 'html.parser')\n",
    "    players = []\n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        # Skip headers\n",
    "        if 'thead' in row.attrs.get(\"class\"):\n",
    "            continue\n",
    "        # Get all the cells\n",
    "        cells = row.find_all(\"td\")\n",
    "        # If its a footer, skip it\n",
    "        if cells[0]['csk'] == 'ZZZZZZ':\n",
    "            continue\n",
    "        d = collections.OrderedDict((\n",
    "            ('year_ID', year),\n",
    "            ('player_ID', cells[0][\"data-append-csv\"]),\n",
    "            ('name_common', cells[0].a.string),\n",
    "        ))\n",
    "        for stat in cells[1:]:\n",
    "            d[stat['data-stat']] = stat.string\n",
    "        players.append(d)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_list:\n",
    "    path = \"./input/standard_player_pitching_stats_{}.csv\".format(year)\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    print(\"Downloading {}\".format(year))\n",
    "    df = pd.DataFrame(get_standard_player_pitching(year))\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for year in year_list:\n",
    "    path = \"./input/standard_player_pitching_stats_{}.csv\".format(year)\n",
    "    df = pd.read_csv(path)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, sort=True)\n",
    "df.to_csv(\"./input/standard_player_pitching_stats_all.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseball reference batters by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standard_player_batting(year):\n",
    "    url = \"https://www.baseball-reference.com/leagues/MLB/{}-standard-batting.shtml\".format(year)\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    comments = soup.find_all(string=lambda text:isinstance(text, Comment))\n",
    "    table = BeautifulSoup(comments[16], 'html.parser')\n",
    "    players = []\n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        # Skip headers\n",
    "        if 'thead' in row.attrs.get(\"class\"):\n",
    "            continue\n",
    "        # Get all the cells\n",
    "        cells = row.find_all(\"td\")\n",
    "        # If its a footer, skip it\n",
    "        if cells[0]['csk'] == 'ZZZZZZ':\n",
    "            continue\n",
    "        d = collections.OrderedDict((\n",
    "            ('year_ID', year),\n",
    "            ('player_ID', cells[0][\"data-append-csv\"]),\n",
    "            ('name_common', cells[0].a.string),\n",
    "        ))\n",
    "        for stat in cells[1:]:\n",
    "            d[stat['data-stat']] = stat.string\n",
    "        players.append(d)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in year_list:\n",
    "    path = \"./input/standard_player_batting_stats_{}.csv\".format(year)\n",
    "    if os.path.exists(path):\n",
    "        continue\n",
    "    print(\"Downloading {}\".format(year))\n",
    "    df = pd.DataFrame(get_standard_player_batting(year))\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for year in year_list:\n",
    "    path = \"./input/standard_player_batting_stats_{}.csv\".format(year)\n",
    "    df = pd.read_csv(path)\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list, sort=True)\n",
    "df.to_csv(\"./input/standard_player_batting_stats_all.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseball reference batter game log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batter_gamelog(player_id, year, force=False):\n",
    "    path = \"./input/player_{}_batting_game_log_{}.csv\".format(player_id, year)\n",
    "    if os.path.exists(path) and not force:\n",
    "        return\n",
    "    url_template = \"https://www.baseball-reference.com/players/gl.fcgi?id={}&t=b&year={}\"\n",
    "    url = url_template.format(player_id, year)\n",
    "    print(\"- Requesting {}\".format(url))\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    table = soup.find('table', id='batting_gamelogs')\n",
    "    game_list = table.findAll('tr', id=lambda x: x and x.startswith('batting_gamelogs'))\n",
    "    print(\"- Scraping {} games\".format(len(game_list)))\n",
    "    stat_list = []\n",
    "    for i, game in enumerate(game_list):\n",
    "        cells = game.find_all(\"td\")\n",
    "        d = collections.OrderedDict()\n",
    "        for stat in cells[1:]:\n",
    "            if 'csk' in stat.attrs.keys():\n",
    "                d[stat['data-stat']] = stat['csk']\n",
    "            else:\n",
    "                d[stat['data-stat']] = stat.string\n",
    "        stat_list.append(d)\n",
    "    df = pd.DataFrame(stat_list)\n",
    "    print(\"- Writing {} rows\".format(len(df)))\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "the2550club = [\n",
    "    [\"cedence01\",1973],\n",
    "    [\"morgajo02\",1973],\n",
    "    [\"cedence01\",1974],\n",
    "    [\"morgajo02\",1976],\n",
    "    [\"sandbry01\",1985],\n",
    "    [\"daviser01\",1986],\n",
    "    [\"henderi01\",1986],\n",
    "    [\"daviser01\",1987],\n",
    "    [\"bondsba01\",1990],\n",
    "    [\"henderi01\",1990],\n",
    "    [\"ramirha01\",2007],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=cedence01&t=b&year=1973\n",
      "- Scraping 139 games\n",
      "- Writing 139 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=morgajo02&t=b&year=1973\n",
      "- Scraping 157 games\n",
      "- Writing 157 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=cedence01&t=b&year=1974\n",
      "- Scraping 160 games\n",
      "- Writing 160 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=morgajo02&t=b&year=1976\n",
      "- Scraping 141 games\n",
      "- Writing 141 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=sandbry01&t=b&year=1985\n",
      "- Scraping 153 games\n",
      "- Writing 153 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=daviser01&t=b&year=1986\n",
      "- Scraping 132 games\n",
      "- Writing 132 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=henderi01&t=b&year=1986\n",
      "- Scraping 153 games\n",
      "- Writing 153 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=daviser01&t=b&year=1987\n",
      "- Scraping 129 games\n",
      "- Writing 129 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=bondsba01&t=b&year=1990\n",
      "- Scraping 151 games\n",
      "- Writing 151 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=henderi01&t=b&year=1990\n",
      "- Scraping 136 games\n",
      "- Writing 136 rows\n",
      "- Requesting https://www.baseball-reference.com/players/gl.fcgi?id=ramirha01&t=b&year=2007\n",
      "- Scraping 154 games\n",
      "- Writing 154 rows\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for player_id, year in the2550club:\n",
    "    path = get_batter_gamelog(player_id, year, force=True)\n",
    "    df = pd.read_csv(path)\n",
    "    df['player_ID'] = player_id\n",
    "    df['year_ID'] = year\n",
    "    df_list.append(df)\n",
    "pd.concat(df_list).to_csv(\"./input/the_2550_club_gamelogs.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FanGraphs starter pitch value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(year):\n",
    "    url_template = \"https://www.fangraphs.com/leaders.aspx?pos=all&stats=sta&lg=all&qual=y&type=7&season=2018&month=0&season1={}&ind=0&team=0&rost=0&age=0&filter=&players=0&page=1_50\"\n",
    "    url = url_template.format(year)\n",
    "    r = r.request(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
